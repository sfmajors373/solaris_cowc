{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping vehicles with `solaris` and the `cowc` dataset\n",
    "\n",
    "`solaris` can assist with tasks beyond foundational mapping. Here, we'll go through a full exercise of preprocessing the Cars Overhead With Context (`cowc`) dataset, training a segmentation model with `solaris`, mapping vehicles in a previously unseen test city, and finally scoring our results.\n",
    "\n",
    "\n",
    "Let's start with downloading our data.  The `cowc` dataset can be [downloaded here.](ftp://gdo152.ucllnl.org/cowc/datasets/ground_truth_sets/)  Save it to a location where you will be able to preprocess the data and enable your GPU to find it.\n",
    "\n",
    "Once all the data in the `ground_truth_sets/` directory is downloaded, we'll import our packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solaris as sol\n",
    "import os\n",
    "import glob\n",
    "import gdal\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.morphology import square, dilation\n",
    "from matplotlib import pyplot as plt\n",
    "from solaris.eval.iou import calculate_iou\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify our directories for pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root= \"/home/sarah/solaris_cowc/cowc/datasets/ground_truth_sets\"  ##cowc ground_truth_sets location after download\n",
    "masks_out= \"/home/sarah/solaris_cowc/cowc/masks\" ##output location for your masks for training\n",
    "images_out= \"/home/sarah/solaris_cowc/cowc/tiles\" ##output location for your tiled images for testing\n",
    "masks_test_out= \"/home/sarah/solaris_cowc/cowc/masks_test\" ##output location for your masks for testing\n",
    "images_test_out= \"/home/sarah/solaris_cowc/cowc/tiles_test\" ##output location for your tiled images for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a tiling function\n",
    "Below is a function for tiling, solaris presently does not handle non-georeferenced pngs, but will in the future.  This is a hold-over function until then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_tile(untiled_image_dir, tiles_out_dir, tile_size=544,\n",
    "             overlap=0.2, search=\".png\",Output_Channels=[1,2,3]):\n",
    "    \"\"\"Function to tile a set of images into smaller square chunks with embedded georeferencing info\n",
    "    allowing an end user to specify the size of the tile, the overlap of each tile, and when to discard\n",
    "    a tile if it contains blank data.\n",
    "    Arguments\n",
    "    ---------\n",
    "    untiled_image_dir : str\n",
    "        Directory containing full or partial image strips that are untiled.\n",
    "        Imagery must be georeferenced.\n",
    "    tiles_out_dir : str\n",
    "        Output directory for tiled imagery.\n",
    "    tile_size : int\n",
    "        Extent of each tile in both X and Y directions in units of pixels.\n",
    "        Defaults to ``544`` .\n",
    "    overlap : float\n",
    "        The amount of overlap of each tile in float format.  Should range between 0 and <1.\n",
    "        Defaults to ``0.2`` .\n",
    "    search : str\n",
    "        A string with a wildcard to search for files by type\n",
    "        Defaults to \".png\"\n",
    "    Output_Channels : list\n",
    "        A list of the number of channels to output, 1 indexed.\n",
    "        Defaults to ``[1,2,3]`` .\n",
    "    Returns\n",
    "    -------\n",
    "    Tiled imagery directly output to the tiles_out_dir\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tiles_out_dir):\n",
    "        os.makedirs(tiles_out_dir)\n",
    "\n",
    "    os.chdir(untiled_image_dir)\n",
    "    search2 = \"*\" + search\n",
    "    images = glob.glob(search2)\n",
    "    tile_size = int(tile_size)\n",
    "\n",
    "    for stackclip in images:\n",
    "        print(stackclip)\n",
    "        interp = gdal.Open(os.path.abspath(stackclip))\n",
    "        width = int(interp.RasterXSize)\n",
    "        height = int(interp.RasterYSize)\n",
    "        count = 0\n",
    "        for i in range(0, width, int(tile_size * (1 - overlap))):\n",
    "            for j in range(0, height, int(tile_size * (1 - overlap))):\n",
    "                Chip = [i, j, tile_size, tile_size]\n",
    "                count += 1\n",
    "                Tileout = tiles_out_dir + \"/\" + \\\n",
    "                    stackclip.split(search)[0] + \"_tile_\" + str(count) + \".tif\"\n",
    "                output = gdal.Translate(Tileout, stackclip, srcWin=Chip, bandList=Output_Channels)\n",
    "                del output\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orgainze our data\n",
    "The `cowc` dataset is a bit cluttered to start, some reogranization helps us down the road for smoother pre-processing of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(root)\n",
    "dirs=glob.glob(\"*/\")\n",
    "'''\n",
    "for directory in dirs:\n",
    "    os.chdir(directory)\n",
    "    if not os.path.exists(\"Images\"):\n",
    "        os.makedirs(\"Images\")\n",
    "        os.makedirs(\"Masks\")\n",
    "        os.makedirs(\"Extras\")\n",
    "    xcfs=glob.glob(\"*.xcf\")\n",
    "    txts=glob.glob(\"*.txt\")\n",
    "    os.chdir(\"Images\")\n",
    "    negatives=glob.glob(\"*Negatives.png\")\n",
    "    masks=glob.glob(\"*Annotated_Cars.png\")\n",
    "    for xcf in xcfs:\n",
    "        shutil.move(xcf,os.path.join(root,directory,\"Extras\",xcf))\n",
    "    for txt in txts:\n",
    "        shutil.move(txt,os.path.join(root,directory,\"Extras\",txt))\n",
    "    for negative in negatives:\n",
    "        shutil.move(negative,os.path.join(root,directory,\"Extras\",negative))\n",
    "    for mask in masks:\n",
    "        shutil.move(mask,os.path.join(root,directory,\"Masks\",mask))\n",
    "    images=glob.glob(\"*.png\")\n",
    "    for image in images:\n",
    "        shutil.move(image,os.path.join(root,directory,\"Images\",image))\n",
    "    os.chdir(root)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile our masks and convert them to GeoTiffs\n",
    "Presently `solaris` works with GeoTiffs exclusively, so converting pngs into this tifs is required to start.  Furthermore tiling is required to feed our neural network. We will tile our masks and images sequentially, this process may take some time depending on your compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for directory in dirs:\n",
    "    if directory != \"Utah_AGRC\":\n",
    "        directory = os.path.join(root,directory,\"Masks\")\n",
    "        print(directory)\n",
    "        geo_tile(directory, masks_out, tile_size=512, overlap=0.1,search=\"*.png\",Output_Channels=[1])\n",
    "    else:\n",
    "        directory = os.path.join(root,directory,\"Masks\")\n",
    "        print(directory)\n",
    "        geo_tile(directory, masks_out, tile_size=512, overlap=0,search=\"*.png\",Output_Channels=[1]) #No overlap for testing.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for directory in dirs:\n",
    "    if directory != \"Utah_AGRC\":\n",
    "        directory = os.path.join(root,directory,\"Images\")\n",
    "        print(directory)\n",
    "        geo_tile(directory, images_out, tile_size=512, overlap=0.1,search=\"*.png\",Output_Channels=[1,2,3])\n",
    "    else:\n",
    "        directory = os.path.join(root,directory,\"Images\")\n",
    "        print(directory)\n",
    "        geo_tile(directory, images_out, tile_size=512, overlap=0,search=\"*.png\",Output_Channels=[1,2,3])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilate our masks to increase the size of our labels\n",
    "Here we will perform a [simple morphological dilation filter](https://scikit-image.org/docs/dev/auto_examples/applications/plot_morphology.html#dilation) to increase our label size.  This will make our masks large enough for our neural network to detect, but not large enough so they start to overlap one another when cars are located in close proximity to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "os.chdir(masks_out)\n",
    "images=glob.glob(\"*.tif\")\n",
    "for image in tqdm(images):\n",
    "    band=gdal.Open(image)\n",
    "    band = band.ReadAsArray()\n",
    "    band=dilation(band, square(9))\n",
    "    im_out = driver.Create(image,band.shape[1],band.shape[0],1,gdal.GDT_Byte)\n",
    "    im_out.GetRasterBand(1).WriteArray(band)\n",
    "    del im_out\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some basic statistics for z-scoring (normalizing) our imagery\n",
    "[Z-scoring](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/z-score/) and normalizing our imagery can help to standardize it, improve generalizability, and potentially the transferability of a model to another location. It also helps to soften overly bright or dark areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "M1=[]\n",
    "M2=[]\n",
    "M3=[]\n",
    "S1=[]\n",
    "S2=[]\n",
    "S3=[]\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "os.chdir(images_out)\n",
    "images=glob.glob(\"*.tif\")\n",
    "for image in images:\n",
    "    band=gdal.Open(image).ReadAsArray()\n",
    "    M1.append(np.mean(band[0,:,:]))\n",
    "    M2.append(np.mean(band[1,:,:]))\n",
    "    M3.append(np.mean(band[2,:,:]))\n",
    "    S1.append(np.std(band[0,:,:]))\n",
    "    S2.append(np.std(band[1,:,:]))\n",
    "    S3.append(np.std(band[2,:,:]))\n",
    "\n",
    "print(\"Save these numbers for your solaris.yml file for training and z-scoring (normalizing) your imagery\")\n",
    "print(np.mean(M1)/255)\n",
    "print(np.mean(M2)/255)\n",
    "print(np.mean(M3)/255)\n",
    "print(np.mean(S1)/255)\n",
    "print(np.mean(S2)/255)\n",
    "print(np.mean(S3)/255)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold out a city for testing\n",
    "Here we hold out Salt Lake City, Utah as a test city, and do some simple data reogranization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if not os.path.exists(images_test_out):\n",
    "        os.makedirs(images_test_out)\n",
    "os.chdir(images_out)\n",
    "images = glob.glob(\"12TVL*\")\n",
    "for image in tqdm(images):\n",
    "    output = os.path.join(images_test_out,image)\n",
    "    shutil.move(image, output)\n",
    "\n",
    "if not os.path.exists(masks_test_out):\n",
    "        os.makedirs(masks_test_out)\n",
    "os.chdir(masks_out)\n",
    "images = glob.glob(\"12TVL*\")\n",
    "for image in tqdm(images):\n",
    "    output = os.path.join(masks_test_out,image)\n",
    "    shutil.move(image, output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review some of our masks and images\n",
    "We can now review some our masks and images, you can change the integer value in the filename to see different tiles easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.path.join(images_test_out,\"12TVL240120.png_tile_99.tif\")\n",
    "mask = os.path.join(masks_test_out,\"12TVL240120_Annotated_Cars.png_tile_99.tif\")\n",
    "image = gdal.Open(image).ReadAsArray()\n",
    "mask = gdal.Open(mask).ReadAsArray()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax[0].imshow(np.moveaxis(image,0,2))\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title('Mask')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a csv file that lists our images and our masks for training and testing\n",
    "`solaris` requires our images and masks to be organized coherently and documents where each image is in a tabular csv format.  These csvs will be linked to in our yml file and can then be used to read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = []\n",
    "images = []\n",
    "image_folder=images_out\n",
    "label_folder=masks_out\n",
    "os.chdir(label_folder)\n",
    "labels=glob.glob(\"*.tif\")\n",
    "for x in labels:\n",
    "    z = x.split('_Annotated_Cars')[0] + x.split('_Annotated_Cars')[1]\n",
    "    os.chdir(image_folder)\n",
    "    image=glob.glob(z)\n",
    "    if len(image) != 1:\n",
    "        os.chdir(label_folder)\n",
    "        os.remove(x)        \n",
    "    else:\n",
    "        images.append(image[0])\n",
    "        \n",
    "for image, label in zip(images,labels):\n",
    "    image = os.path.join(image_folder,image)\n",
    "    label = os.path.join(label_folder,label)\n",
    "    data.append((image, label))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['image', 'label'])\n",
    "df.to_csv(os.path.join(root,\"train_data_cowc2.csv\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = []\n",
    "images = []\n",
    "image_folder=images_test_out\n",
    "label_folder=masks_test_out\n",
    "os.chdir(label_folder)\n",
    "labels=glob.glob(\"*.tif\")\n",
    "for x in labels:\n",
    "    z = x.split('_Annotated_Cars')[0] + x.split('_Annotated_Cars')[1]\n",
    "    os.chdir(image_folder)\n",
    "    image=glob.glob(z)\n",
    "    if len(image) != 1:\n",
    "        os.chdir(label_folder)\n",
    "        os.remove(x)        \n",
    "    else:\n",
    "        images.append(image[0])\n",
    "        \n",
    "for image, label in zip(images,labels):\n",
    "    image = os.path.join(image_folder,image)\n",
    "    label = os.path.join(label_folder,label)\n",
    "    data.append((image, label))\n",
    "\n",
    "df = pd.DataFrame(data, columns=['image', 'label'])\n",
    "df.to_csv(os.path.join(root,\"test_data_cowc2.csv\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit your .yml file and begin training your model\n",
    "An [example yml file is provided here](https://github.com/jshermeyer/solaris_cowc/blob/master/xdxd_vehicleDetection.yml). Be sure the train paramenter is set to `True`.  Furthermore, be sure to pass the paths to your csvs that you just created into the `training_data_csv` and `inference_data_csv` prompts.  Optionally you may want to alter the `batch_size` or `val_holdout_frac` which is the fraction of images randomly sampled out of your training set to help your model learn as it trains.  Also ensure that your `Normalize` values are correct.\n",
    "\n",
    "When you're ready, set the path you your modified yml file and run the prompt below.  Training time can take multiple hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = sol.utils.config.parse('/home/sarah/solaris_cowc/xdxd_vehicleDetection.yml')\n",
    "trainer = sol.nets.train.Trainer(config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to inference\n",
    "Be sure to edit your yml to enable infer mode and then we can start inferencing to find the vehicles in Salt Lake City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df = sol.nets.infer.get_infer_df(config)\n",
    "inferer = sol.nets.infer.Inferer(config)\n",
    "inferer(inf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify our directories for post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output=\"/home/sarah/solaris_cowc/inference_out/\"  ## The location that you output inference results to as specified in your yml.\n",
    "inference_output_bin=\"/home/sarah/solaris_cowc/inference_out_binary\"  ## A location to store binarized outputs\n",
    "inference_polygon_dir=\"/home/sarah/solaris_cowc/inference_polys\" ## Outputs polygonized\n",
    "ground_truth_polygon_dir=\"/home/sarah/solaris_cowc/ground_truth_polys\" ## Ground Truth Outputs polygonized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing- binarize our masks and convert them to polygons\n",
    "Here we will binarize our outputs and convert a mask to a 1/0 value for car/no car.  Following this we will convert the masks to polygons.  You may want to adjust the cutoff value for binarization based on your own experiments or change this if you chose not to z-score your imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solaris.vector.mask import mask_to_poly_geojson\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "\n",
    "os.chdir(inference_output)\n",
    "images=glob.glob(\"*.tif\")\n",
    "for image in tqdm(images):\n",
    "    band=gdal.Open(image)\n",
    "    band = band.ReadAsArray()\n",
    "    band[np.where((band > 0))] = 1  ### Note that these values may be model specific and change slightly due to reimplementations.  For simplicity I threshold at 0.\n",
    "    band[np.where((band <= 0))] = 0\n",
    "    im_out = driver.Create(os.path.join(inference_output_bin,image),band.shape[1],band.shape[0],1,gdal.GDT_Byte)\n",
    "    im_out.GetRasterBand(1).WriteArray(band)\n",
    "    del im_out\n",
    "    output=os.path.join(inference_polygon_dir,image.split(\".\")[0]+\".geojson\")\n",
    "    gdf=mask_to_poly_geojson(band,reference_im=os.path.join(images_test_out,image),min_area=1,simplify=True)\n",
    "    if not gdf.empty:\n",
    "        gdf.to_file(output, driver='GeoJSON')\n",
    "        \n",
    "        \n",
    "os.chdir(masks_test_out)\n",
    "images=glob.glob(\"*.tif\")\n",
    "for image in tqdm(images):\n",
    "    band=gdal.Open(image)\n",
    "    band = band.ReadAsArray()\n",
    "    #output=os.path.join(ground_truth_polygon_dir,image.split(\".\")[0]+\".geojson\")\n",
    "    output=os.path.join(ground_truth_polygon_dir,image.split(\"_Annotated_Cars\")[0]+\".geojson\")\n",
    "    image=image.split(\"_Annotated_Cars\")[0]+image.split(\"_Annotated_Cars\")[1]\n",
    "    gdf=mask_to_poly_geojson(band,reference_im=os.path.join(images_test_out,image),min_area=1,simplify=True)\n",
    "    if not gdf.empty:\n",
    "        gdf.to_file(output, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out our results\n",
    "Below we can inspect our results, and compare vs. the ground truth mask.  Again the integer value can be changed in each filename to inspect different tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = os.path.join(images_test_out,\"12TVL240120.png_tile_99.tif\")\n",
    "mask = os.path.join(masks_test_out,\"12TVL240120_Annotated_Cars.png_tile_99.tif\")\n",
    "prediction = os.path.join(inference_output_bin,\"12TVL240120.png_tile_99.tif\")\n",
    "image = gdal.Open(image).ReadAsArray()\n",
    "mask = gdal.Open(mask).ReadAsArray()\n",
    "prediction = gdal.Open(prediction).ReadAsArray()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax[0].imshow(np.moveaxis(image,0,2))\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title('Ground Truth Mask')\n",
    "ax[2].imshow(prediction)\n",
    "ax[2].set_title('Prediction')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a few more functions for scoring our results. \n",
    "Here we will work with the [solaris.eval.iou.calculate_iou()](../../api/eval.rst#solaris.eval.iou) function to calculate [intersection over union](https://en.wikipedia.org/wiki/Jaccard_index) and from this [precision and recall.](https://en.wikipedia.org/wiki/Precision_and_recall)  This can be used to score how well our model is performing at detecting cars.\n",
    "The calculate_ious function's arguments:\n",
    "\n",
    "- `pred_poly` : A `shapely.Polygon`.  This is a prediction polygon to test.\n",
    "- `test_data_GDF` : A `geopandas.GeoDataFrame`.  This is GeoDataFrame of ground truth polygons to test ``pred_poly`` against.\n",
    "\n",
    "Using the function as is will calculate precision, but we can actually \"invert\" the inputs to calculate recall as well.  For the recall caluclation instead of supplying a prediciton polygon we will supply a ground-truth polygon.  Furthermore, instead of supplying a ground truth geodataframe containing all of our ground truth polygons for a tile we will supply a geodataframe containing all of the prediction polygons for a tile.\n",
    "\n",
    "We can initialize the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper functions for calculate_iou\n",
    "\n",
    "def precision_calc(proposal_polygons_dir,groundtruth_polygons_dir,file_format=\"geojson\"):\n",
    "    ious=[]\n",
    "    os.chdir(proposal_polygons_dir)\n",
    "    search = \"*\" + file_format\n",
    "    proposal_geojsons=glob.glob(search)\n",
    "    for geojson in tqdm(proposal_geojsons):\n",
    "        print(geojson)\n",
    "        ground_truth_poly = os.path.join(groundtruth_polygons_dir,geojson)\n",
    "        if os.path.exists(ground_truth_poly):\n",
    "            print('path exists')\n",
    "            ground_truth_gdf=gpd.read_file(ground_truth_poly)\n",
    "            proposal_gdf=gpd.read_file(geojson)\n",
    "            for index, row in (proposal_gdf.iterrows()):\n",
    "                iou=calculate_iou(row.geometry, ground_truth_gdf)\n",
    "                print(iou)\n",
    "                if 'iou_score' in iou.columns:\n",
    "                    iou=iou.iou_score.max()\n",
    "                    ious.append(iou)\n",
    "                else:\n",
    "                    iou=0\n",
    "                    ious.append(iou)\n",
    "    return ious\n",
    "\n",
    "# proposal_polygon_dir = \"/home/sarah/solaris_cowc/inference_polys\"\n",
    "# groundtruth_polygons_dir = \"/home/sarah/solaris_cowc/ground_truth_polys\"\n",
    "\n",
    "def recall_calc(proposal_polygons_dir,groundtruth_polygons_dir,file_format=\"geojson\"):\n",
    "    ious=[]\n",
    "    os.chdir(groundtruth_polygons_dir)\n",
    "    search = \"*\" + file_format\n",
    "    gt_geojsons=glob.glob(search)\n",
    "    for geojson in tqdm(gt_geojsons):\n",
    "        proposal_poly = os.path.join(proposal_polygons_dir,geojson)\n",
    "        if os.path.exists(proposal_poly):\n",
    "            proposal_gdf=gpd.read_file(proposal_poly)\n",
    "            gt_gdf=gpd.read_file(geojson)\n",
    "            for index, row in (gt_gdf.iterrows()):\n",
    "                iou=calculate_iou(row.geometry, proposal_gdf)\n",
    "                if 'iou_score' in iou.columns:\n",
    "                    iou=iou.iou_score.max()\n",
    "                    ious.append(iou)\n",
    "                else:\n",
    "                    iou=0\n",
    "                    ious.append(iou)\n",
    "    return ious\n",
    "    \n",
    "def f1_score(precision_ious,recall_ious,threshold=0.5):\n",
    "    items=[]\n",
    "    for i in precision_ious:\n",
    "        if i >=threshold:\n",
    "            items.append(1)\n",
    "        else:\n",
    "            items.append(0)\n",
    "    \n",
    "    precision= np.mean(items)\n",
    "    \n",
    "    items=[]\n",
    "    for i in recall_ious:\n",
    "        if i >=threshold:\n",
    "            items.append(1)\n",
    "        else:\n",
    "            items.append(0)\n",
    "    recall= np.mean(items)\n",
    "    \n",
    "    f1 = 2* precision * recall/(precision + recall)\n",
    "    return f1\n",
    "\n",
    "def simple_average_precision(precisions_ious,threshold=0.5):\n",
    "    items=[]\n",
    "    for i in precision_ious:\n",
    "        if i >=threshold:\n",
    "            items.append(1)\n",
    "        else:\n",
    "            items.append(0)\n",
    "    \n",
    "    precision= np.mean(items)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score our results\n",
    "As a final step we can score our outputs against the ground truth to report scores.  Without these scores all you really have is a pretty picture.  We report both an [F1 Score](https://en.wikipedia.org/wiki/F1_score) and an [average precision score](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score our results\n",
    "precision_ious = precision_calc(inference_polygon_dir,ground_truth_polygon_dir,file_format=\"geojson\")\n",
    "print(precision_ious)\n",
    "recall_ious = recall_calc(inference_polygon_dir,ground_truth_polygon_dir,file_format=\"geojson\")\n",
    "print(recall_ious)\n",
    "print(f1_score(precision_ious,recall_ious,threshold=0.25), \"F1 Score@0.25\")\n",
    "print(f1_score(precision_ious,recall_ious,threshold=0.5), \"F1 Score@0.5\") ## The traditional SpaceNet metric\n",
    "print(simple_average_precision(precision_ious,threshold=0.25), \"AP@0.25\") ## Acceptable for small objects like cars!\n",
    "print(simple_average_precision(precision_ious,threshold=0.5), \"AP@0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyGrid time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything before this has come from the solaris [tutorials](https://github.com/CosmiQ/solaris/blob/master/docs/tutorials/notebooks/map_vehicles_cowc.ipynb) with very little changed by me.  Just things to make it work on my machine.  Now I am moving to tryiing to implement this with PySyft and PyGrid.  (Expect more excerpts from tutorials moving forward.)(Eventually, I will clean this up and make it cohesive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyGrid is running in the background: \n",
    "Gateway: 5000, \n",
    "bob: 3000, \n",
    "alice: 3001, \n",
    "bill: 3002, \n",
    "james: 3003 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/lib/python3.8/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_2.1.0.so'\n",
      "/usr/lib/python3.8/site-packages/grid/__init__.py:15: Warning: This library is DEPRECATED and should be deleted soon. To use the grid features use the syft.grid module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import grid as gr\n",
    "import syft as sy\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Connect directly to grid nodes\n",
    "nodes = [\"ws://localhost:3000/\",\n",
    "         \"ws://localhost:3001/\",\n",
    "         \"ws://localhost:3002/\",\n",
    "         \"ws://localhost:3003\"]\n",
    "\n",
    "compute_nodes = []\n",
    "for node in nodes:\n",
    "    compute_nodes.append( gr.WebsocketGridClient(hook, node) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_out= \"/home/sarah/solaris_cowc/cowc/masks\" ##output location for your masks for training\n",
    "images_out= \"/home/sarah/solaris_cowc/cowc/tiles\" ##output location for your tiled images for testing\n",
    "masks_test_out= \"/home/sarah/solaris_cowc/cowc/masks_test\" ##output location for your masks for testing\n",
    "images_test_out= \"/home/sarah/solaris_cowc/cowc/tiles_test\" ##output location for your tiled images for testing\n",
    "\n",
    "config = sol.utils.config.parse('/home/sarah/solaris_cowc/xdxd_vehicleDetection.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tiles = []\n",
    "tag_masks = []\n",
    "os.chdir(images_out)\n",
    "tiles = glob.glob(\"*.tif\")\n",
    "os.chdir(masks_out)\n",
    "masks = glob.glob(\"*.tif\")\n",
    "os.chdir(images_test_out)\n",
    "tiles_test = glob.glob(\"*.tif\")\n",
    "os.chdir(masks_test_out)\n",
    "masks_test = glob.glob(\"*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = sol.nets.train.get_train_val_dfs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next function returns a Dataloader\n",
    "train_dataloader = sol.nets.datagen.make_data_generator('torch', config, train_df, stage='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = sol.nets.datagen.make_data_generator('torch', config, val_df, stage='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataloader into tiles and masks\n",
    "dataiter = iter(train_dataloader)\n",
    "tiles_train_cowc, masks_train_cowc = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(int(len(tiles_train_cowc)/len(compute_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str or None, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36munwrap_args_from_function\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mambiguous_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Load the utility function to transform the args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36mbuild_get_tensor_type\u001b[0;34m(rules, layer)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;31m# Note that we return also args_type which helps handling case 3 in the docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             new_args, new_kwargs, new_type, args_type = hook_args.unwrap_args_from_function(\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_args_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36munwrap_args_from_function\u001b[0;34m(attr, args, kwargs, return_args_type)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Update the function in case of an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         args_hook_function, get_tensor_type_function = build_unwrap_args_from_function(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36mbuild_unwrap_args_from_function\u001b[0;34m(args, return_tuple)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# tensor found in the args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mget_tensor_type_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_get_tensor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0margs_hook_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_tensor_type_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook_args.py\u001b[0m in \u001b[0;36mbuild_get_tensor_type\u001b[0;34m(rules, layer)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;31m# the un-hooked (so native) function which is perfect in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPureFrameworkTensorFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPureFrameworkTensorFoundError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5d170c58d3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_cowc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles_train_cowc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles_train_cowc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tuple of chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmasks_cowc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_train_cowc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_train_cowc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/trace.py\u001b[0m in \u001b[0;36mtrace_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mhandle_func_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_func_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_func_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mhandle_func_command\u001b[0;34m(cls, command)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;31m# in the execute_command function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;31m# Change the library path to avoid errors on layers like AvgPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(cmd, args, kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mcommand_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"native_{command}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# split_size_or_sections. The branching code is in tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str or None, not float"
     ]
    }
   ],
   "source": [
    "# Split tiles and masks dataloader pieces into chunks for workers\n",
    "dataset_cowc = torch.split(tiles_train_cowc, (len(tiles_train_cowc)/len(compute_nodes))) # tuple of chunks\n",
    "masks_cowc = torch.split(masks_train_cowc, (len(masks_train_cowc) / len(compute_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the chunks\n",
    "for i in range(len(compute_nodes)):\n",
    "    print(tiles[i])\n",
    "    tag_tiles.append(dataset_cowc[i].tag(\"#X\", \"#solaris_cowc\", \"#dataset\").describe(\"Input tiles of solaris_cowc dataset\"))\n",
    "    tag_masks.append(masks_cowc[i].tag(\"#Y\", \"solaris_cowc\", \"#dataset\").describe(\"Input masks of solaris_cowc dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
